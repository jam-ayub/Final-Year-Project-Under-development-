{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "transsexual-system",
   "metadata": {
    "id": "transsexual-system"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pediatric-stomach",
   "metadata": {
    "id": "pediatric-stomach",
    "outputId": "b8320fa9-e00f-4f14-83e7-53ff7b7710e1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "#df = pd.read_excel('training_set_rel3.xls')\n",
    "#df = pd.read_csv('training_set_rel3(full_dataset).tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "corresponding-forge",
   "metadata": {
    "id": "corresponding-forge",
    "outputId": "4395855b-11d5-4dc4-8273-6a653ea2879d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'domain1_score'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['rater3_domain1', 'rater1_domain2', 'rater2_domain2',\n",
    "                       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
    "                        'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
    "                       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
    "                       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
    "                        'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'rater1_domain1', 'rater2_domain1'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "historical-report",
   "metadata": {
    "id": "historical-report",
    "outputId": "51948f8a-8498-481b-9947-5e0436e593a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0            8.0  \n",
       "1            9.0  \n",
       "2            7.0  \n",
       "3           10.0  \n",
       "4            8.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "british-newton",
   "metadata": {
    "id": "british-newton",
    "outputId": "2eaa6a57-eb73-42fe-9484-9010d6291de5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">essay_id</th>\n",
       "      <th colspan=\"8\" halign=\"left\">essay_set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain1_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>419.0</td>\n",
       "      <td>10332.035800</td>\n",
       "      <td>2286.169678</td>\n",
       "      <td>5985.0</td>\n",
       "      <td>9312.00</td>\n",
       "      <td>9936.0</td>\n",
       "      <td>10441.50</td>\n",
       "      <td>16629.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>4.174224</td>\n",
       "      <td>0.735761</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1736.0</td>\n",
       "      <td>9736.028226</td>\n",
       "      <td>2948.863117</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>7129.75</td>\n",
       "      <td>9519.5</td>\n",
       "      <td>12033.00</td>\n",
       "      <td>16618.0</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>3.989055</td>\n",
       "      <td>0.981909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2445.0</td>\n",
       "      <td>10349.193456</td>\n",
       "      <td>3606.369687</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7143.00</td>\n",
       "      <td>10093.0</td>\n",
       "      <td>13052.00</td>\n",
       "      <td>18958.0</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>4.191820</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2830.0</td>\n",
       "      <td>10060.071731</td>\n",
       "      <td>4784.706422</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4641.25</td>\n",
       "      <td>10476.0</td>\n",
       "      <td>15046.50</td>\n",
       "      <td>19010.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>4.090813</td>\n",
       "      <td>1.607430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1424.0</td>\n",
       "      <td>8540.226826</td>\n",
       "      <td>5449.974753</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3755.75</td>\n",
       "      <td>4574.5</td>\n",
       "      <td>14933.25</td>\n",
       "      <td>19450.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>3.576545</td>\n",
       "      <td>1.831185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>96.0</td>\n",
       "      <td>4042.343750</td>\n",
       "      <td>3292.721955</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>4403.75</td>\n",
       "      <td>19122.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>1.109321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>137.0</td>\n",
       "      <td>3614.197080</td>\n",
       "      <td>6304.502357</td>\n",
       "      <td>14.0</td>\n",
       "      <td>552.00</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>1647.00</td>\n",
       "      <td>19493.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.927007</td>\n",
       "      <td>2.116584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>163.0</td>\n",
       "      <td>3889.717791</td>\n",
       "      <td>6746.520512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>478.50</td>\n",
       "      <td>966.0</td>\n",
       "      <td>1563.50</td>\n",
       "      <td>19492.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.030675</td>\n",
       "      <td>2.270104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>737.0</td>\n",
       "      <td>2107.493894</td>\n",
       "      <td>4492.543052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>516.00</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1436.00</td>\n",
       "      <td>19550.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1.407056</td>\n",
       "      <td>1.509878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>383.0</td>\n",
       "      <td>3199.415144</td>\n",
       "      <td>5923.081845</td>\n",
       "      <td>2.0</td>\n",
       "      <td>583.50</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1584.50</td>\n",
       "      <td>19544.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1.767624</td>\n",
       "      <td>2.006742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>372.0</td>\n",
       "      <td>3567.693548</td>\n",
       "      <td>6421.140345</td>\n",
       "      <td>4.0</td>\n",
       "      <td>496.25</td>\n",
       "      <td>1040.5</td>\n",
       "      <td>1583.25</td>\n",
       "      <td>21619.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>1.905914</td>\n",
       "      <td>2.155484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>165.0</td>\n",
       "      <td>6935.260606</td>\n",
       "      <td>8471.107969</td>\n",
       "      <td>24.0</td>\n",
       "      <td>628.00</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>18284.00</td>\n",
       "      <td>19511.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.036364</td>\n",
       "      <td>2.849670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>133.0</td>\n",
       "      <td>12365.511278</td>\n",
       "      <td>8586.825178</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1170.00</td>\n",
       "      <td>18134.0</td>\n",
       "      <td>18944.00</td>\n",
       "      <td>19558.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>4.879699</td>\n",
       "      <td>2.878967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>82.0</td>\n",
       "      <td>18781.024390</td>\n",
       "      <td>528.580372</td>\n",
       "      <td>17836.0</td>\n",
       "      <td>18283.50</td>\n",
       "      <td>18803.5</td>\n",
       "      <td>19297.25</td>\n",
       "      <td>19541.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>105.0</td>\n",
       "      <td>18723.752381</td>\n",
       "      <td>509.671459</td>\n",
       "      <td>17849.0</td>\n",
       "      <td>18301.00</td>\n",
       "      <td>18700.0</td>\n",
       "      <td>19191.00</td>\n",
       "      <td>19554.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>18755.779070</td>\n",
       "      <td>563.725077</td>\n",
       "      <td>17834.0</td>\n",
       "      <td>18211.00</td>\n",
       "      <td>18872.0</td>\n",
       "      <td>19146.25</td>\n",
       "      <td>20954.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7.011628</td>\n",
       "      <td>0.107833</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>199.0</td>\n",
       "      <td>18720.020101</td>\n",
       "      <td>513.500081</td>\n",
       "      <td>17841.0</td>\n",
       "      <td>18293.00</td>\n",
       "      <td>18729.0</td>\n",
       "      <td>19191.00</td>\n",
       "      <td>19559.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>160.0</td>\n",
       "      <td>18676.606250</td>\n",
       "      <td>474.669234</td>\n",
       "      <td>17838.0</td>\n",
       "      <td>18215.50</td>\n",
       "      <td>18759.5</td>\n",
       "      <td>19078.25</td>\n",
       "      <td>19525.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>118.0</td>\n",
       "      <td>18655.389831</td>\n",
       "      <td>502.406653</td>\n",
       "      <td>17842.0</td>\n",
       "      <td>18235.50</td>\n",
       "      <td>18605.5</td>\n",
       "      <td>19076.00</td>\n",
       "      <td>19555.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>18817.068182</td>\n",
       "      <td>494.739472</td>\n",
       "      <td>17846.0</td>\n",
       "      <td>18426.50</td>\n",
       "      <td>18906.5</td>\n",
       "      <td>19202.00</td>\n",
       "      <td>19561.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>103.0</td>\n",
       "      <td>18787.320388</td>\n",
       "      <td>638.762026</td>\n",
       "      <td>17874.0</td>\n",
       "      <td>18282.50</td>\n",
       "      <td>18725.0</td>\n",
       "      <td>19106.50</td>\n",
       "      <td>21389.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7.038835</td>\n",
       "      <td>0.194146</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>18762.842857</td>\n",
       "      <td>669.944939</td>\n",
       "      <td>17854.0</td>\n",
       "      <td>18228.00</td>\n",
       "      <td>18661.0</td>\n",
       "      <td>19158.75</td>\n",
       "      <td>21408.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.028571</td>\n",
       "      <td>0.167802</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>18810.444444</td>\n",
       "      <td>601.507991</td>\n",
       "      <td>17906.0</td>\n",
       "      <td>18364.50</td>\n",
       "      <td>18770.0</td>\n",
       "      <td>19271.50</td>\n",
       "      <td>21489.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.015873</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>18706.301887</td>\n",
       "      <td>456.474221</td>\n",
       "      <td>17840.0</td>\n",
       "      <td>18419.00</td>\n",
       "      <td>18657.0</td>\n",
       "      <td>19192.00</td>\n",
       "      <td>19518.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>18786.121212</td>\n",
       "      <td>615.376876</td>\n",
       "      <td>17858.0</td>\n",
       "      <td>18362.50</td>\n",
       "      <td>18775.0</td>\n",
       "      <td>19145.50</td>\n",
       "      <td>21140.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.030303</td>\n",
       "      <td>0.172292</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>21400.200000</td>\n",
       "      <td>216.543760</td>\n",
       "      <td>21031.0</td>\n",
       "      <td>21399.00</td>\n",
       "      <td>21463.0</td>\n",
       "      <td>21553.00</td>\n",
       "      <td>21555.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>21117.250000</td>\n",
       "      <td>271.625201</td>\n",
       "      <td>20721.0</td>\n",
       "      <td>21063.00</td>\n",
       "      <td>21208.5</td>\n",
       "      <td>21262.75</td>\n",
       "      <td>21331.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>21135.833333</td>\n",
       "      <td>251.920159</td>\n",
       "      <td>20838.0</td>\n",
       "      <td>21021.00</td>\n",
       "      <td>21079.5</td>\n",
       "      <td>21198.00</td>\n",
       "      <td>21579.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>21238.909091</td>\n",
       "      <td>254.876619</td>\n",
       "      <td>20828.0</td>\n",
       "      <td>21057.50</td>\n",
       "      <td>21248.0</td>\n",
       "      <td>21476.50</td>\n",
       "      <td>21512.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>21029.750000</td>\n",
       "      <td>199.766828</td>\n",
       "      <td>20831.0</td>\n",
       "      <td>20922.50</td>\n",
       "      <td>20937.0</td>\n",
       "      <td>21082.50</td>\n",
       "      <td>21369.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>21203.040816</td>\n",
       "      <td>288.925088</td>\n",
       "      <td>20719.0</td>\n",
       "      <td>20925.00</td>\n",
       "      <td>21257.0</td>\n",
       "      <td>21448.00</td>\n",
       "      <td>21624.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>21144.558824</td>\n",
       "      <td>273.926023</td>\n",
       "      <td>20727.0</td>\n",
       "      <td>20940.25</td>\n",
       "      <td>21172.0</td>\n",
       "      <td>21365.25</td>\n",
       "      <td>21596.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>21162.729730</td>\n",
       "      <td>278.790109</td>\n",
       "      <td>20762.0</td>\n",
       "      <td>20910.00</td>\n",
       "      <td>21103.0</td>\n",
       "      <td>21434.00</td>\n",
       "      <td>21628.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>21096.843750</td>\n",
       "      <td>291.619074</td>\n",
       "      <td>20746.0</td>\n",
       "      <td>20799.25</td>\n",
       "      <td>21071.5</td>\n",
       "      <td>21301.50</td>\n",
       "      <td>21620.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>21138.358974</td>\n",
       "      <td>252.040357</td>\n",
       "      <td>20716.0</td>\n",
       "      <td>20916.00</td>\n",
       "      <td>21160.0</td>\n",
       "      <td>21338.50</td>\n",
       "      <td>21582.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>21225.468085</td>\n",
       "      <td>261.109660</td>\n",
       "      <td>20741.0</td>\n",
       "      <td>21073.50</td>\n",
       "      <td>21192.0</td>\n",
       "      <td>21456.00</td>\n",
       "      <td>21626.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>21162.876923</td>\n",
       "      <td>250.214003</td>\n",
       "      <td>20733.0</td>\n",
       "      <td>20968.00</td>\n",
       "      <td>21129.0</td>\n",
       "      <td>21350.00</td>\n",
       "      <td>21617.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>21179.871795</td>\n",
       "      <td>232.110135</td>\n",
       "      <td>20779.0</td>\n",
       "      <td>21010.50</td>\n",
       "      <td>21189.0</td>\n",
       "      <td>21360.50</td>\n",
       "      <td>21566.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21175.600000</td>\n",
       "      <td>266.073278</td>\n",
       "      <td>20747.0</td>\n",
       "      <td>20908.25</td>\n",
       "      <td>21237.0</td>\n",
       "      <td>21376.50</td>\n",
       "      <td>21558.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>21268.125000</td>\n",
       "      <td>259.060631</td>\n",
       "      <td>20770.0</td>\n",
       "      <td>21161.75</td>\n",
       "      <td>21276.5</td>\n",
       "      <td>21460.25</td>\n",
       "      <td>21586.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>161.0</td>\n",
       "      <td>21153.006211</td>\n",
       "      <td>262.583308</td>\n",
       "      <td>20718.0</td>\n",
       "      <td>20935.00</td>\n",
       "      <td>21144.0</td>\n",
       "      <td>21348.00</td>\n",
       "      <td>21633.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>21236.045455</td>\n",
       "      <td>240.634771</td>\n",
       "      <td>20725.0</td>\n",
       "      <td>21043.75</td>\n",
       "      <td>21328.0</td>\n",
       "      <td>21421.75</td>\n",
       "      <td>21564.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>21176.913043</td>\n",
       "      <td>255.081611</td>\n",
       "      <td>20743.0</td>\n",
       "      <td>21007.50</td>\n",
       "      <td>21185.0</td>\n",
       "      <td>21384.00</td>\n",
       "      <td>21611.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>21095.266667</td>\n",
       "      <td>218.887273</td>\n",
       "      <td>20734.0</td>\n",
       "      <td>20933.50</td>\n",
       "      <td>21092.0</td>\n",
       "      <td>21241.50</td>\n",
       "      <td>21510.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21158.857143</td>\n",
       "      <td>296.051674</td>\n",
       "      <td>20728.0</td>\n",
       "      <td>20913.50</td>\n",
       "      <td>21118.5</td>\n",
       "      <td>21381.75</td>\n",
       "      <td>21621.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>21133.322581</td>\n",
       "      <td>284.789558</td>\n",
       "      <td>20736.0</td>\n",
       "      <td>20844.50</td>\n",
       "      <td>21110.0</td>\n",
       "      <td>21391.00</td>\n",
       "      <td>21567.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>21252.384615</td>\n",
       "      <td>236.152683</td>\n",
       "      <td>20717.0</td>\n",
       "      <td>21122.00</td>\n",
       "      <td>21306.0</td>\n",
       "      <td>21413.00</td>\n",
       "      <td>21563.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>21168.857143</td>\n",
       "      <td>284.105279</td>\n",
       "      <td>20759.0</td>\n",
       "      <td>20995.50</td>\n",
       "      <td>21146.0</td>\n",
       "      <td>21343.50</td>\n",
       "      <td>21599.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21260.333333</td>\n",
       "      <td>301.818378</td>\n",
       "      <td>21056.0</td>\n",
       "      <td>21087.00</td>\n",
       "      <td>21118.0</td>\n",
       "      <td>21362.50</td>\n",
       "      <td>21607.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21059.000000</td>\n",
       "      <td>325.269119</td>\n",
       "      <td>20829.0</td>\n",
       "      <td>20944.00</td>\n",
       "      <td>21059.0</td>\n",
       "      <td>21174.00</td>\n",
       "      <td>21289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>21275.615385</td>\n",
       "      <td>252.095729</td>\n",
       "      <td>20769.0</td>\n",
       "      <td>21120.00</td>\n",
       "      <td>21385.0</td>\n",
       "      <td>21484.00</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21125.000000</td>\n",
       "      <td>429.920923</td>\n",
       "      <td>20821.0</td>\n",
       "      <td>20973.00</td>\n",
       "      <td>21125.0</td>\n",
       "      <td>21277.00</td>\n",
       "      <td>21429.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20826.0</td>\n",
       "      <td>20826.00</td>\n",
       "      <td>20826.0</td>\n",
       "      <td>20826.00</td>\n",
       "      <td>20826.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              essay_id                                                         \\\n",
       "                 count          mean          std      min       25%      50%   \n",
       "domain1_score                                                                   \n",
       "0.0              419.0  10332.035800  2286.169678   5985.0   9312.00   9936.0   \n",
       "1.0             1736.0   9736.028226  2948.863117   2979.0   7129.75   9519.5   \n",
       "2.0             2445.0  10349.193456  3606.369687     41.0   7143.00  10093.0   \n",
       "3.0             2830.0  10060.071731  4784.706422     22.0   4641.25  10476.0   \n",
       "4.0             1424.0   8540.226826  5449.974753     19.0   3755.75   4574.5   \n",
       "5.0               96.0   4042.343750  3292.721955     50.0   3194.25   3878.0   \n",
       "6.0              137.0   3614.197080  6304.502357     14.0    552.00   1041.0   \n",
       "7.0              163.0   3889.717791  6746.520512      3.0    478.50    966.0   \n",
       "8.0              737.0   2107.493894  4492.543052      1.0    516.00    963.0   \n",
       "9.0              383.0   3199.415144  5923.081845      2.0    583.50   1100.0   \n",
       "10.0             372.0   3567.693548  6421.140345      4.0    496.25   1040.5   \n",
       "11.0             165.0   6935.260606  8471.107969     24.0    628.00   1349.0   \n",
       "12.0             133.0  12365.511278  8586.825178     16.0   1170.00  18134.0   \n",
       "13.0              82.0  18781.024390   528.580372  17836.0  18283.50  18803.5   \n",
       "14.0             105.0  18723.752381   509.671459  17849.0  18301.00  18700.0   \n",
       "15.0              86.0  18755.779070   563.725077  17834.0  18211.00  18872.0   \n",
       "16.0             199.0  18720.020101   513.500081  17841.0  18293.00  18729.0   \n",
       "17.0             160.0  18676.606250   474.669234  17838.0  18215.50  18759.5   \n",
       "18.0             118.0  18655.389831   502.406653  17842.0  18235.50  18605.5   \n",
       "19.0              88.0  18817.068182   494.739472  17846.0  18426.50  18906.5   \n",
       "20.0             103.0  18787.320388   638.762026  17874.0  18282.50  18725.0   \n",
       "21.0              70.0  18762.842857   669.944939  17854.0  18228.00  18661.0   \n",
       "22.0              63.0  18810.444444   601.507991  17906.0  18364.50  18770.0   \n",
       "23.0              53.0  18706.301887   456.474221  17840.0  18419.00  18657.0   \n",
       "24.0              99.0  18786.121212   615.376876  17858.0  18362.50  18775.0   \n",
       "25.0               5.0  21400.200000   216.543760  21031.0  21399.00  21463.0   \n",
       "26.0               4.0  21117.250000   271.625201  20721.0  21063.00  21208.5   \n",
       "27.0               6.0  21135.833333   251.920159  20838.0  21021.00  21079.5   \n",
       "28.0              11.0  21238.909091   254.876619  20828.0  21057.50  21248.0   \n",
       "29.0               8.0  21029.750000   199.766828  20831.0  20922.50  20937.0   \n",
       "30.0              49.0  21203.040816   288.925088  20719.0  20925.00  21257.0   \n",
       "31.0              34.0  21144.558824   273.926023  20727.0  20940.25  21172.0   \n",
       "32.0              37.0  21162.729730   278.790109  20762.0  20910.00  21103.0   \n",
       "33.0              32.0  21096.843750   291.619074  20746.0  20799.25  21071.5   \n",
       "34.0              39.0  21138.358974   252.040357  20716.0  20916.00  21160.0   \n",
       "35.0              47.0  21225.468085   261.109660  20741.0  21073.50  21192.0   \n",
       "36.0              65.0  21162.876923   250.214003  20733.0  20968.00  21129.0   \n",
       "37.0              39.0  21179.871795   232.110135  20779.0  21010.50  21189.0   \n",
       "38.0              20.0  21175.600000   266.073278  20747.0  20908.25  21237.0   \n",
       "39.0               8.0  21268.125000   259.060631  20770.0  21161.75  21276.5   \n",
       "40.0             161.0  21153.006211   262.583308  20718.0  20935.00  21144.0   \n",
       "41.0              22.0  21236.045455   240.634771  20725.0  21043.75  21328.0   \n",
       "42.0              23.0  21176.913043   255.081611  20743.0  21007.50  21185.0   \n",
       "43.0              15.0  21095.266667   218.887273  20734.0  20933.50  21092.0   \n",
       "44.0              14.0  21158.857143   296.051674  20728.0  20913.50  21118.5   \n",
       "45.0              31.0  21133.322581   284.789558  20736.0  20844.50  21110.0   \n",
       "46.0              13.0  21252.384615   236.152683  20717.0  21122.00  21306.0   \n",
       "47.0               7.0  21168.857143   284.105279  20759.0  20995.50  21146.0   \n",
       "48.0               3.0  21260.333333   301.818378  21056.0  21087.00  21118.0   \n",
       "49.0               2.0  21059.000000   325.269119  20829.0  20944.00  21059.0   \n",
       "50.0              13.0  21275.615385   252.095729  20769.0  21120.00  21385.0   \n",
       "55.0               2.0  21125.000000   429.920923  20821.0  20973.00  21125.0   \n",
       "60.0               1.0  20826.000000          NaN  20826.0  20826.00  20826.0   \n",
       "\n",
       "                                 essay_set                                     \\\n",
       "                    75%      max     count      mean       std  min  25%  50%   \n",
       "domain1_score                                                                   \n",
       "0.0            10441.50  16629.0     419.0  4.174224  0.735761  3.0  4.0  4.0   \n",
       "1.0            12033.00  16618.0    1736.0  3.989055  0.981909  2.0  3.0  4.0   \n",
       "2.0            13052.00  18958.0    2445.0  4.191820  1.204709  1.0  3.0  4.0   \n",
       "3.0            15046.50  19010.0    2830.0  4.090813  1.607430  1.0  2.0  4.0   \n",
       "4.0            14933.25  19450.0    1424.0  3.576545  1.831185  1.0  2.0  2.0   \n",
       "5.0             4403.75  19122.0      96.0  2.031250  1.109321  1.0  2.0  2.0   \n",
       "6.0             1647.00  19493.0     137.0  1.927007  2.116584  1.0  1.0  1.0   \n",
       "7.0             1563.50  19492.0     163.0  2.030675  2.270104  1.0  1.0  1.0   \n",
       "8.0             1436.00  19550.0     737.0  1.407056  1.509878  1.0  1.0  1.0   \n",
       "9.0             1584.50  19544.0     383.0  1.767624  2.006742  1.0  1.0  1.0   \n",
       "10.0            1583.25  21619.0     372.0  1.905914  2.155484  1.0  1.0  1.0   \n",
       "11.0           18284.00  19511.0     165.0  3.036364  2.849670  1.0  1.0  1.0   \n",
       "12.0           18944.00  19558.0     133.0  4.879699  2.878967  1.0  1.0  7.0   \n",
       "13.0           19297.25  19541.0      82.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "14.0           19191.00  19554.0     105.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "15.0           19146.25  20954.0      86.0  7.011628  0.107833  7.0  7.0  7.0   \n",
       "16.0           19191.00  19559.0     199.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "17.0           19078.25  19525.0     160.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "18.0           19076.00  19555.0     118.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "19.0           19202.00  19561.0      88.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "20.0           19106.50  21389.0     103.0  7.038835  0.194146  7.0  7.0  7.0   \n",
       "21.0           19158.75  21408.0      70.0  7.028571  0.167802  7.0  7.0  7.0   \n",
       "22.0           19271.50  21489.0      63.0  7.015873  0.125988  7.0  7.0  7.0   \n",
       "23.0           19192.00  19518.0      53.0  7.000000  0.000000  7.0  7.0  7.0   \n",
       "24.0           19145.50  21140.0      99.0  7.030303  0.172292  7.0  7.0  7.0   \n",
       "25.0           21553.00  21555.0       5.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "26.0           21262.75  21331.0       4.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "27.0           21198.00  21579.0       6.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "28.0           21476.50  21512.0      11.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "29.0           21082.50  21369.0       8.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "30.0           21448.00  21624.0      49.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "31.0           21365.25  21596.0      34.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "32.0           21434.00  21628.0      37.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "33.0           21301.50  21620.0      32.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "34.0           21338.50  21582.0      39.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "35.0           21456.00  21626.0      47.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "36.0           21350.00  21617.0      65.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "37.0           21360.50  21566.0      39.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "38.0           21376.50  21558.0      20.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "39.0           21460.25  21586.0       8.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "40.0           21348.00  21633.0     161.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "41.0           21421.75  21564.0      22.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "42.0           21384.00  21611.0      23.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "43.0           21241.50  21510.0      15.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "44.0           21381.75  21621.0      14.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "45.0           21391.00  21567.0      31.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "46.0           21413.00  21563.0      13.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "47.0           21343.50  21599.0       7.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "48.0           21362.50  21607.0       3.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "49.0           21174.00  21289.0       2.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "50.0           21484.00  21532.0      13.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "55.0           21277.00  21429.0       2.0  8.000000  0.000000  8.0  8.0  8.0   \n",
       "60.0           20826.00  20826.0       1.0  8.000000       NaN  8.0  8.0  8.0   \n",
       "\n",
       "                         \n",
       "               75%  max  \n",
       "domain1_score            \n",
       "0.0            4.0  6.0  \n",
       "1.0            5.0  6.0  \n",
       "2.0            5.0  7.0  \n",
       "3.0            6.0  7.0  \n",
       "4.0            6.0  7.0  \n",
       "5.0            2.0  7.0  \n",
       "6.0            1.0  7.0  \n",
       "7.0            1.0  7.0  \n",
       "8.0            1.0  7.0  \n",
       "9.0            1.0  7.0  \n",
       "10.0           1.0  8.0  \n",
       "11.0           7.0  7.0  \n",
       "12.0           7.0  7.0  \n",
       "13.0           7.0  7.0  \n",
       "14.0           7.0  7.0  \n",
       "15.0           7.0  8.0  \n",
       "16.0           7.0  7.0  \n",
       "17.0           7.0  7.0  \n",
       "18.0           7.0  7.0  \n",
       "19.0           7.0  7.0  \n",
       "20.0           7.0  8.0  \n",
       "21.0           7.0  8.0  \n",
       "22.0           7.0  8.0  \n",
       "23.0           7.0  7.0  \n",
       "24.0           7.0  8.0  \n",
       "25.0           8.0  8.0  \n",
       "26.0           8.0  8.0  \n",
       "27.0           8.0  8.0  \n",
       "28.0           8.0  8.0  \n",
       "29.0           8.0  8.0  \n",
       "30.0           8.0  8.0  \n",
       "31.0           8.0  8.0  \n",
       "32.0           8.0  8.0  \n",
       "33.0           8.0  8.0  \n",
       "34.0           8.0  8.0  \n",
       "35.0           8.0  8.0  \n",
       "36.0           8.0  8.0  \n",
       "37.0           8.0  8.0  \n",
       "38.0           8.0  8.0  \n",
       "39.0           8.0  8.0  \n",
       "40.0           8.0  8.0  \n",
       "41.0           8.0  8.0  \n",
       "42.0           8.0  8.0  \n",
       "43.0           8.0  8.0  \n",
       "44.0           8.0  8.0  \n",
       "45.0           8.0  8.0  \n",
       "46.0           8.0  8.0  \n",
       "47.0           8.0  8.0  \n",
       "48.0           8.0  8.0  \n",
       "49.0           8.0  8.0  \n",
       "50.0           8.0  8.0  \n",
       "55.0           8.0  8.0  \n",
       "60.0           8.0  8.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('domain1_score').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "characteristic-broadway",
   "metadata": {
    "id": "characteristic-broadway"
   },
   "outputs": [],
   "source": [
    "#df = df.dropna()\n",
    "df['essay'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "macro-injection",
   "metadata": {
    "id": "macro-injection",
    "outputId": "dbbe7e19-4be3-4148-f0dc-fa5e1cefe744"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('domain1_score', axis = 1)\n",
    "len(X['essay'][0])\n",
    "#print(X['essay'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "happy-journalist",
   "metadata": {
    "id": "happy-journalist"
   },
   "outputs": [],
   "source": [
    "y = df['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "behavioral-tackle",
   "metadata": {
    "id": "behavioral-tackle",
    "outputId": "dc006e63-e581-409e-c24c-ede3b0cb15d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "educational-sending",
   "metadata": {
    "id": "educational-sending",
    "outputId": "cec12b00-5b26-4df4-c376-0c03f4811bf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['domain1_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "appreciated-criticism",
   "metadata": {
    "id": "appreciated-criticism",
    "outputId": "b56697aa-4833-4e06-f8d1-34b8f08fe4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        8.0\n",
       "1        9.0\n",
       "2        7.0\n",
       "3       10.0\n",
       "4        8.0\n",
       "        ... \n",
       "1778     8.0\n",
       "1779     7.0\n",
       "1780     8.0\n",
       "1781     2.0\n",
       "1782     7.0\n",
       "Name: domain1_score, Length: 1783, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['essay_set']==1]['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "central-slovakia",
   "metadata": {
    "id": "central-slovakia"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-0be3e92a650a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'domain1_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jamay\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7763\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7764\u001b[0m         )\n\u001b[1;32m-> 7765\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jamay\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jamay\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jamay\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-0be3e92a650a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'domain1_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-0be3e92a650a>\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(x, mi, ma)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#print(\"After Normalization : \"+str(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'domain1_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "min_range = [2,1,0,0,0,0,0,0]\n",
    "max_range = [12,6,3,3,4,4,30,60]\n",
    "\n",
    "def normalize(x,mi,ma):\n",
    "    #print(\"Before Normalization: \"+str(x))\n",
    "    x = (x-mi)/(ma-mi)\n",
    "    #print(\"After Normalization : \"+str(x))\n",
    "    return round(x*10)\n",
    "\n",
    "df['final_score']=df.apply(lambda x:normalize(x['domain1_score'],min_range[x['essay_set']-1],max_range[x['essay_set']-1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intensive-preliminary",
   "metadata": {
    "id": "intensive-preliminary",
    "outputId": "dc14daab-fa7b-4263-c131-168494843870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       7\n",
       "2       5\n",
       "3       8\n",
       "4       6\n",
       "       ..\n",
       "493     7\n",
       "494     7\n",
       "495    10\n",
       "496     7\n",
       "497     8\n",
       "Name: final_score, Length: 498, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['final_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "peripheral-dinner",
   "metadata": {
    "id": "peripheral-dinner",
    "outputId": "7bf5d417-4f2d-46e2-f577-04496710c36c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  final_score  \n",
       "0              8            6  \n",
       "1              9            7  \n",
       "2              7            5  \n",
       "3             10            8  \n",
       "4              8            6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "saved-adjustment",
   "metadata": {
    "id": "saved-adjustment"
   },
   "outputs": [],
   "source": [
    "df.drop('domain1_score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adolescent-drove",
   "metadata": {
    "id": "adolescent-drove"
   },
   "outputs": [],
   "source": [
    "y = df['final_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expired-marks",
   "metadata": {
    "id": "expired-marks",
    "outputId": "93a4b2d1-f157-430d-bbd3-2d489551fa6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "double-evolution",
   "metadata": {
    "id": "double-evolution",
    "outputId": "152e21d8-3ea7-4a62-b30b-f25ca720ecfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "solar-conviction",
   "metadata": {
    "id": "solar-conviction",
    "outputId": "addc9f64-5bf6-4c01-9692-b8f6b88ea4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "peaceful-lottery",
   "metadata": {
    "id": "peaceful-lottery"
   },
   "outputs": [],
   "source": [
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "violent-aurora",
   "metadata": {
    "id": "violent-aurora"
   },
   "outputs": [],
   "source": [
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "defensive-diving",
   "metadata": {
    "id": "defensive-diving"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "separate-shame",
   "metadata": {
    "id": "separate-shame"
   },
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer\n",
    "#ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "word_Lemmatized = WordNetLemmatizer()\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "essays = X.copy()\n",
    "corpus = []\n",
    "for i in range (0, len(essays)):\n",
    "    #print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', essays['essay'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [word_Lemmatized.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dutch-index",
   "metadata": {
    "id": "dutch-index",
    "outputId": "6f89ba43-6643-454c-caa3-79cf43f1ef24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dear location think computer negative affect u many people ace camputer daily america num many people go least hour num mean num people cant exercise wasting many posibility physical cap sound good think everything done write letter got got material sit back done writing put material away put letter mailbox walk way back well think write email sitdown move finger see difference cap instead getting good walk friend house talk er know literally computer instead around add anything computer give away information information lead everthing wouldbe gone go online believe phisically get hurt computer long num thing computer cap happened grandpa wood chair day get ardthritis muscle cap thing th'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eastern-donor",
   "metadata": {
    "id": "eastern-donor"
   },
   "outputs": [],
   "source": [
    "#onehot_rep = [one_hot(words, voc_size) for words in corpus]\n",
    "#onehot_rep [0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "gross-house",
   "metadata": {
    "id": "gross-house"
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"cnn_filter_sizes\": [128, 128, 128],\n",
    "    \"cnn_kernel_sizes\": [5, 5, 5],\n",
    "    \"cnn_pooling_sizes\": [5, 5, 40],\n",
    "    \"constraint_learning_rate\": 0.01,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"embedding_trainable\": False,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"max_num_words\": 10000,\n",
    "    \"max_sequence_length\": 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "logical-equation",
   "metadata": {
    "id": "logical-equation"
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=hparams[\"max_num_words\"])\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "text_sequences = tokenizer.texts_to_sequences(corpus)\n",
    "#text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "suspended-simon",
   "metadata": {
    "id": "suspended-simon",
    "outputId": "9578940d-7af9-40e4-ae7c-3a250557816a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47 113  79 ...   0   0   0]\n",
      " [ 47   3   3 ...   0   0   0]\n",
      " [ 47   3   3 ...   0   0   0]\n",
      " ...\n",
      " [127  31 513 ...   2  50 295]\n",
      " [ 59   2  12 ...   0   0   0]\n",
      " [ 47 113 157 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "sent_length = 1875\n",
    "embedded_docs = pad_sequences(text_sequences,padding='post',maxlen=hparams[\"max_sequence_length\"])\n",
    "\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "retired-foster",
   "metadata": {
    "id": "retired-foster",
    "outputId": "23fb8b60-adb0-4148-aac3-897c99165a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.200d.txt', encoding=\"utf8\")\n",
    "for line in f: \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "powered-tours",
   "metadata": {
    "id": "powered-tours"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "from numpy import zeros\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = zeros((vocab_size, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-county",
   "metadata": {
    "id": "qualified-prime"
   },
   "source": [
    "## Creating the model_1\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D\n",
    "embedding_vector_features=50\n",
    "model=Sequential()\n",
    "e = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "#model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.add(LSTM(100, dropout=0.4, recurrent_dropout=0.2, input_shape=[1, 300], return_sequences=True))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['mean_squared_error'])\n",
    "#model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-search",
   "metadata": {
    "id": "interstate-panel"
   },
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot1.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-anniversary",
   "metadata": {
    "id": "accepted-programmer"
   },
   "source": [
    "## Creating the model_2\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D\n",
    "\n",
    "embedding_vector_features=50\n",
    "\n",
    "model=Sequential()\n",
    "e = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(LSTM(100, dropout=0.4, recurrent_dropout=0.2, input_shape=[1, 300], return_sequences=True))\n",
    "model.add(Bidirectional(LSTM(64, recurrent_dropout=0.2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-ivory",
   "metadata": {
    "id": "statewide-magnitude"
   },
   "source": [
    "plot_model(model, to_file='model_plot2.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sexual-momentum",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 2357,
     "status": "error",
     "timestamp": 1638992727353,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "empirical-flooring",
    "outputId": "07b4c0ce-88de-462a-f7ba-e8eab7178f93",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 250, 200)     1325400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 250, 64)      38464       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 250, 64)      25664       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 100)          100400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 228)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           14656       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            17          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,507,209\n",
      "Trainable params: 181,809\n",
      "Non-trainable params: 1,325,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Creating the model_3\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D, concatenate, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_model():\n",
    "    embedding_vector_features=50\n",
    "    # define set of input\n",
    "    deep_inputs = Input(shape=hparams[\"max_sequence_length\"],)\n",
    "\n",
    "    embedding_layer = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=4, trainable=False, mask_zero=True)(deep_inputs)\n",
    "\n",
    "    # the first branch operates on the first input\n",
    "    x = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(embedding_layer)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    xx = Conv1D(filters=64, kernel_size=2, padding='same', activation='relu')(embedding_layer)\n",
    "    xx = GlobalAveragePooling1D()(xx)\n",
    "\n",
    "\n",
    "    # the second branch opreates on the second input Bidirectional(\n",
    "    y = Bidirectional(LSTM(50, recurrent_dropout=0.2, return_sequences=False))(embedding_layer)\n",
    "\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([x,xx,y])\n",
    "    #combined = concatenate()[x, xx, y]\n",
    "\n",
    "    # apply a FC layer and then a regression prediction on the combined outputs\n",
    "    out = Dense(64, activation=\"relu\")(combined)\n",
    "    #out = tf.keras.layers.BatchNormalization()(out)\n",
    "    #out = Dropout(0.2)(out)\n",
    "\n",
    "    out = Dense(32, activation=\"relu\")(out)\n",
    "    #out = tf.keras.layers.BatchNormalization()(out)\n",
    "    #out = Dropout(0.2)(out)\n",
    "\n",
    "    out = Dense(16, activation=\"relu\")(out)\n",
    "\n",
    "    out = Dense(1, activation=\"linear\")(out)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=deep_inputs, outputs=out)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-gates",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "aborted",
     "timestamp": 1638992727322,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "standing-guest"
   },
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-translator",
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "aborted",
     "timestamp": 1638992727325,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "surprising-oracle",
    "scrolled": true
   },
   "source": [
    "from tensorflow.keras.utils import plot_model \n",
    "plot_model(model, to_file='model_plot4.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fossil-shoulder",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "aborted",
     "timestamp": 1638992727326,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "fossil-shoulder"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "unnecessary-belgium",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "aborted",
     "timestamp": 1638992727329,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "unnecessary-belgium"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47, 113,  79, ...,   0,   0,   0],\n",
       "       [ 47,   3,   3, ...,   0,   0,   0],\n",
       "       [ 47,   3,   3, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [127,  31, 513, ...,   2,  50, 295],\n",
       "       [ 59,   2,  12, ...,   0,   0,   0],\n",
       "       [ 47, 113, 157, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "under-snake",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1638992727331,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "under-snake"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16,    6, 2154, ...,    1,   38,  120],\n",
       "       [ 101,    1,   23, ...,    0,    0,    0],\n",
       "       [ 101,  611, 1622, ...,   69,  373,   41],\n",
       "       ...,\n",
       "       [   1,   23,    6, ...,    0,    0,    0],\n",
       "       [  58,    2,  135, ...,    0,    0,    0],\n",
       "       [  47,    3,    3, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "animal-phone",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1638992727334,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "animal-phone"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 17s 1s/step - loss: 37.7178 - mean_squared_error: 37.7178 - val_loss: 24.8665 - val_mean_squared_error: 24.8665\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 24.86649, saving model to checkpoint.h5\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 6s 921ms/step - loss: 15.4555 - mean_squared_error: 15.4555 - val_loss: 3.3686 - val_mean_squared_error: 3.3686\n",
      "\n",
      "Epoch 00002: val_loss improved from 24.86649 to 3.36863, saving model to checkpoint.h5\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 6s 959ms/step - loss: 2.9067 - mean_squared_error: 2.9067 - val_loss: 5.2085 - val_mean_squared_error: 5.2085\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.36863\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 5s 913ms/step - loss: 4.0652 - mean_squared_error: 4.0652 - val_loss: 1.6703 - val_mean_squared_error: 1.6703\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.36863 to 1.67033, saving model to checkpoint.h5\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 6s 942ms/step - loss: 1.8080 - mean_squared_error: 1.8080 - val_loss: 2.3799 - val_mean_squared_error: 2.3799\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.67033\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 6s 960ms/step - loss: 2.2091 - mean_squared_error: 2.2091 - val_loss: 1.8432 - val_mean_squared_error: 1.8432\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.67033\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5734 - mean_squared_error: 1.5734 - val_loss: 1.5356 - val_mean_squared_error: 1.5356\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.67033 to 1.53561, saving model to checkpoint.h5\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 6s 993ms/step - loss: 1.5607 - mean_squared_error: 1.5607 - val_loss: 1.5216 - val_mean_squared_error: 1.5216\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.53561 to 1.52161, saving model to checkpoint.h5\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4456 - mean_squared_error: 1.4456 - val_loss: 1.4307 - val_mean_squared_error: 1.4307\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.52161 to 1.43069, saving model to checkpoint.h5\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 6s 988ms/step - loss: 1.3546 - mean_squared_error: 1.3546 - val_loss: 1.4356 - val_mean_squared_error: 1.4356\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.43069\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 6s 963ms/step - loss: 1.3284 - mean_squared_error: 1.3284 - val_loss: 1.3845 - val_mean_squared_error: 1.3845\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.43069 to 1.38453, saving model to checkpoint.h5\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 6s 935ms/step - loss: 1.2594 - mean_squared_error: 1.2594 - val_loss: 1.3436 - val_mean_squared_error: 1.3436\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.38453 to 1.34363, saving model to checkpoint.h5\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2227 - mean_squared_error: 1.2227 - val_loss: 1.3192 - val_mean_squared_error: 1.3192\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.34363 to 1.31918, saving model to checkpoint.h5\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 5s 921ms/step - loss: 1.1777 - mean_squared_error: 1.1777 - val_loss: 1.3017 - val_mean_squared_error: 1.3017\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.31918 to 1.30167, saving model to checkpoint.h5\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 6s 935ms/step - loss: 1.1474 - mean_squared_error: 1.1474 - val_loss: 1.2782 - val_mean_squared_error: 1.2782\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.30167 to 1.27823, saving model to checkpoint.h5\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 6s 958ms/step - loss: 1.0996 - mean_squared_error: 1.0996 - val_loss: 1.2626 - val_mean_squared_error: 1.2626\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.27823 to 1.26265, saving model to checkpoint.h5\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 6s 950ms/step - loss: 1.0627 - mean_squared_error: 1.0627 - val_loss: 1.2307 - val_mean_squared_error: 1.2307\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.26265 to 1.23071, saving model to checkpoint.h5\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 6s 947ms/step - loss: 1.0272 - mean_squared_error: 1.0272 - val_loss: 1.2091 - val_mean_squared_error: 1.2091\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.23071 to 1.20912, saving model to checkpoint.h5\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 6s 982ms/step - loss: 0.9925 - mean_squared_error: 0.9925 - val_loss: 1.1883 - val_mean_squared_error: 1.1883\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.20912 to 1.18831, saving model to checkpoint.h5\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.9512 - mean_squared_error: 0.9512 - val_loss: 1.1717 - val_mean_squared_error: 1.1717\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.18831 to 1.17169, saving model to checkpoint.h5\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.9051 - mean_squared_error: 0.9051 - val_loss: 1.1646 - val_mean_squared_error: 1.1646\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.17169 to 1.16462, saving model to checkpoint.h5\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.8782 - mean_squared_error: 0.8782 - val_loss: 1.1297 - val_mean_squared_error: 1.1297\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.16462 to 1.12972, saving model to checkpoint.h5\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.8318 - mean_squared_error: 0.8318 - val_loss: 1.1570 - val_mean_squared_error: 1.1570\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.12972\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 6s 996ms/step - loss: 0.8012 - mean_squared_error: 0.8012 - val_loss: 1.1344 - val_mean_squared_error: 1.1344\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.12972\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 6s 936ms/step - loss: 0.7720 - mean_squared_error: 0.7720 - val_loss: 1.1303 - val_mean_squared_error: 1.1303\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.12972\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = 'checkpoint.h5', verbose = 1, save_best_only = True, save_weights_only = False)\n",
    "earlyStop = EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 1, mode = 'auto')\n",
    "\n",
    "callbacksList = [checkpoint, earlyStop]\n",
    "## Training \n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=500,batch_size=64, callbacks = callbacksList)\n",
    "\n",
    "model.load_weights(\"checkpoint.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "finite-gauge",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1638992727335,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "finite-gauge"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "intellectual-hawaii",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1638992727336,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "intellectual-hawaii"
   },
   "outputs": [],
   "source": [
    "## from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D\n",
    "## Creating model\n",
    "## embedding_vector_features=40\n",
    "## model=Sequential()\n",
    "## model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "## model.add(Dropout(0.3))\n",
    "## model.add(LSTM(100))\n",
    "## model.add(Dropout(0.3))\n",
    "## model.add(Dense(1,activation='sigmoid'))\n",
    "## model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "distant-sunset",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "aborted",
     "timestamp": 1638992727339,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "distant-sunset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:1.13\n",
      "Root Mean squared error:1.06\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "#X_test\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error:%.2f\"%mean_squared_error(y_test,y_pred))\n",
    "print(\"Root Mean squared error:%.2f\"%np.sqrt(mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "clinical-class",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "aborted",
     "timestamp": 1638992727340,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "clinical-class"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5, 10,  8,  7,  9,  6,  8,  6,  7,  7,  6,  6,  6,  6,  6,  5,\n",
       "        8,  8,  6,  8,  9,  6,  6,  5,  6,  8,  5,  8,  5,  6,  8,  8,  5,\n",
       "        8,  6,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  6,  8,  6,  9,\n",
       "        6,  6, 10,  2,  6,  6,  7,  6,  7,  6,  5,  5,  8,  8, 10,  6,  8,\n",
       "        6,  7,  5,  8,  6, 10,  7,  8,  9,  8,  5,  6,  6,  7,  9,  8,  8,\n",
       "        3,  8,  6,  7,  7,  6,  8,  6,  8, 10,  7,  8,  4,  8,  7,  7,  6,\n",
       "        5,  6,  4,  5,  7,  9,  7,  7,  8,  7,  8,  4,  7,  6,  6,  6,  6,\n",
       "        7, 10, 10,  7,  8,  4,  6,  8,  6,  9,  9,  6,  5,  6,  6,  6,  6,\n",
       "        6,  6,  5,  8,  6,  5,  9,  5,  5,  8,  6,  6,  6,  6,  6,  5,  8,\n",
       "        4, 10,  6,  9,  7,  8,  6,  8,  6,  2,  8,  6], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cooked-rough",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "aborted",
     "timestamp": 1638992727342,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "cooked-rough"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.148088 ],\n",
       "       [6.617607 ],\n",
       "       [7.986351 ],\n",
       "       [6.741458 ],\n",
       "       [6.0841274],\n",
       "       [8.194379 ],\n",
       "       [5.9210715],\n",
       "       [7.87213  ],\n",
       "       [7.0481896],\n",
       "       [7.283901 ],\n",
       "       [8.627767 ],\n",
       "       [5.576251 ],\n",
       "       [5.88008  ],\n",
       "       [6.9556103],\n",
       "       [5.8780403],\n",
       "       [7.0311747],\n",
       "       [6.8986835],\n",
       "       [8.386816 ],\n",
       "       [5.9591403],\n",
       "       [6.646431 ],\n",
       "       [8.680591 ],\n",
       "       [8.165513 ],\n",
       "       [6.098136 ],\n",
       "       [7.2813897],\n",
       "       [4.8956456],\n",
       "       [6.197837 ],\n",
       "       [8.172848 ],\n",
       "       [5.3252077],\n",
       "       [7.870454 ],\n",
       "       [5.2678113],\n",
       "       [7.1674943],\n",
       "       [8.426665 ],\n",
       "       [8.305725 ],\n",
       "       [6.2113605],\n",
       "       [5.799363 ],\n",
       "       [7.2116375],\n",
       "       [6.9682064],\n",
       "       [7.1509957],\n",
       "       [5.9049788],\n",
       "       [5.922588 ],\n",
       "       [6.701441 ],\n",
       "       [6.7894697],\n",
       "       [6.57765  ],\n",
       "       [6.9491186],\n",
       "       [5.9374156],\n",
       "       [6.6122484],\n",
       "       [6.0305386],\n",
       "       [5.5909777],\n",
       "       [7.692382 ],\n",
       "       [5.554374 ],\n",
       "       [6.761462 ],\n",
       "       [6.2152534],\n",
       "       [5.7068005],\n",
       "       [8.281227 ],\n",
       "       [1.003066 ],\n",
       "       [6.130665 ],\n",
       "       [5.920487 ],\n",
       "       [6.2036777],\n",
       "       [6.1578474],\n",
       "       [7.195697 ],\n",
       "       [5.99319  ],\n",
       "       [4.595064 ],\n",
       "       [5.129119 ],\n",
       "       [6.808505 ],\n",
       "       [7.66739  ],\n",
       "       [7.662856 ],\n",
       "       [6.3021536],\n",
       "       [7.1221848],\n",
       "       [6.426449 ],\n",
       "       [7.467397 ],\n",
       "       [5.772089 ],\n",
       "       [8.085771 ],\n",
       "       [5.6487846],\n",
       "       [7.4344335],\n",
       "       [7.1107845],\n",
       "       [7.8013706],\n",
       "       [7.9443274],\n",
       "       [6.2572007],\n",
       "       [4.2678456],\n",
       "       [5.855098 ],\n",
       "       [5.8930836],\n",
       "       [8.770155 ],\n",
       "       [8.006512 ],\n",
       "       [7.713252 ],\n",
       "       [7.4267654],\n",
       "       [4.5192347],\n",
       "       [7.227829 ],\n",
       "       [5.7660675],\n",
       "       [6.720125 ],\n",
       "       [6.8853884],\n",
       "       [6.8670464],\n",
       "       [7.37148  ],\n",
       "       [6.45703  ],\n",
       "       [7.2889657],\n",
       "       [7.9258165],\n",
       "       [7.5662203],\n",
       "       [6.7701893],\n",
       "       [5.0263195],\n",
       "       [7.1260767],\n",
       "       [6.821887 ],\n",
       "       [6.268838 ],\n",
       "       [5.635229 ],\n",
       "       [5.770525 ],\n",
       "       [6.355663 ],\n",
       "       [5.172074 ],\n",
       "       [5.2604923],\n",
       "       [8.389523 ],\n",
       "       [7.758504 ],\n",
       "       [6.822118 ],\n",
       "       [7.681759 ],\n",
       "       [8.111073 ],\n",
       "       [6.8038583],\n",
       "       [8.001045 ],\n",
       "       [4.609466 ],\n",
       "       [5.9411764],\n",
       "       [5.2155275],\n",
       "       [6.0951896],\n",
       "       [6.3113003],\n",
       "       [6.0134544],\n",
       "       [6.7998657],\n",
       "       [8.083799 ],\n",
       "       [8.010241 ],\n",
       "       [7.0668573],\n",
       "       [8.916605 ],\n",
       "       [6.5341086],\n",
       "       [6.0715976],\n",
       "       [9.542214 ],\n",
       "       [6.819479 ],\n",
       "       [8.166165 ],\n",
       "       [7.500575 ],\n",
       "       [6.9675236],\n",
       "       [4.860458 ],\n",
       "       [6.136026 ],\n",
       "       [6.236361 ],\n",
       "       [6.1766477],\n",
       "       [5.52168  ],\n",
       "       [6.3502274],\n",
       "       [6.5522394],\n",
       "       [6.114244 ],\n",
       "       [7.9700594],\n",
       "       [6.6622486],\n",
       "       [5.6998653],\n",
       "       [8.555738 ],\n",
       "       [6.16336  ],\n",
       "       [6.3136435],\n",
       "       [8.28156  ],\n",
       "       [4.912771 ],\n",
       "       [5.9125476],\n",
       "       [5.996476 ],\n",
       "       [5.5092654],\n",
       "       [6.7995257],\n",
       "       [4.7313232],\n",
       "       [8.652968 ],\n",
       "       [4.589798 ],\n",
       "       [8.388973 ],\n",
       "       [6.021089 ],\n",
       "       [4.481961 ],\n",
       "       [6.8165207],\n",
       "       [8.03377  ],\n",
       "       [5.992179 ],\n",
       "       [6.273526 ],\n",
       "       [5.7479663],\n",
       "       [3.94341  ],\n",
       "       [3.5844302],\n",
       "       [7.5569534]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "oriental-cement",
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "aborted",
     "timestamp": 1638992727343,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "oriental-cement"
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "spread-session",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "aborted",
     "timestamp": 1638992727347,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "spread-session"
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "corporate-venice",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "aborted",
     "timestamp": 1638992727349,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "corporate-venice"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa Score: 0.6688311688311688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "y_pred = np.around(y_pred)\n",
    "result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"Kappa Score: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-aruba",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "aborted",
     "timestamp": 1638992727350,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "hollywood-aruba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-finish",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1638992727352,
     "user": {
      "displayName": "Jam Ayub",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05190088083428677608"
     },
     "user_tz": 480
    },
    "id": "systematic-finish"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Functional API with LSTM Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
